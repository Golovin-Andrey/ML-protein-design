{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DhDTplxk8Hc"
      },
      "source": [
        "# Дизайн белок-белковых взаимодействий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fieXzJ_FlYck"
      },
      "source": [
        "*весь код - для запуска в колабе. перед запуском включите gpu*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOC_oXArPfyi"
      },
      "source": [
        "## 0. Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fRcCFlltVCat"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies for RFDiffusion\n",
        "\n",
        "import os, time, signal\n",
        "import sys, random, string, re\n",
        "if not os.path.isdir(\"params\"):\n",
        "  os.system(\"apt-get install aria2\")\n",
        "  os.system(\"mkdir params\")\n",
        "  # send param download into background\n",
        "  os.system(\"(\\\n",
        "  aria2c -q -x 16 https://files.ipd.uw.edu/krypton/schedules.zip; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/6f5902ac237024bdd0c176cb93063dc4/Base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/e29311f6f1bf1af907f9ef9f44b8328b/Complex_base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/f572d396fae9206628714fb2ce00f72e/Complex_beta_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/5532d2e1f3a4738decd58b19d633b3c3/ActiveSite_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/60f09a193fb5e5ccdc4980417708dbab/Complex_Fold_base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; \\\n",
        "  touch params/done.txt) &\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion\"):\n",
        "  print(\"installing RFdiffusion...\")\n",
        "  os.system(\"git clone https://github.com/sokrypton/RFdiffusion.git\")\n",
        "  os.system(\"pip -q install jedi omegaconf hydra-core icecream pyrsistent\")\n",
        "  os.system(\"pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html\")\n",
        "  os.system(\"cd RFdiffusion/env/SE3Transformer; pip -q install --no-cache-dir -r requirements.txt; pip -q install .\")\n",
        "  os.system(\"wget -qnc https://files.ipd.uw.edu/krypton/ananas\")\n",
        "  os.system(\"chmod +x ananas\")\n",
        "\n",
        "if not os.path.isdir(\"colabdesign\"):\n",
        "  print(\"installing ColabDesign...\")\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion/models\"):\n",
        "  print(\"downloading RFdiffusion params...\")\n",
        "  os.system(\"mkdir RFdiffusion/models\")\n",
        "  models = [\"Base_ckpt.pt\",\"Complex_base_ckpt.pt\",\"Complex_beta_ckpt.pt\",'ActiveSite_ckpt.pt','Complex_Fold_base_ckpt.pt']\n",
        "  for m in models:\n",
        "    while os.path.isfile(f\"{m}.aria2\"):\n",
        "      time.sleep(5)\n",
        "  os.system(f\"mv {' '.join(models)} RFdiffusion/models\")\n",
        "  os.system(\"unzip schedules.zip; rm schedules.zip\")\n",
        "\n",
        "if 'RFdiffusion' not in sys.path:\n",
        "  os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "  sys.path.append('RFdiffusion')\n",
        "\n",
        "if not os.path.isdir('pyrosetta'):\n",
        "    os.system(\"gdown 1Pts0USd16GAtqz5v_4ErTu_7YBpysF9G; \\\n",
        "               pip install pyrosetta-2023.45+release.a6d9ba8-cp310-cp310-linux_x86_64.whl\")\n",
        "\n",
        "os.system(\"pip install py3Dmol\")\n",
        "os.system(\"pip install Bio\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggNQgrf05Gb3"
      },
      "outputs": [],
      "source": [
        "from Bio import PDB\n",
        "from Bio.PDB.PDBParser import PDBParser\n",
        "import py3Dmol\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKEOlbYWmCoF"
      },
      "source": [
        "## 1. Постановка задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Mb1q6klZcG"
      },
      "source": [
        "Будем генерировать белок, способный связывать эктодомен рецептора инсулина (https://www.rcsb.org/structure/5KQV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqqfhkUtl441"
      },
      "source": [
        "Загрузим файл со структурой и визуализируем ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlaHunAsPgow"
      },
      "outputs": [],
      "source": [
        "! wget https://files.rcsb.org/download/5KQV.pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2A74MXUvYFI"
      },
      "outputs": [],
      "source": [
        "parser=PDBParser(QUIET=True)\n",
        "structure=parser.get_structure(\"5KQV\",'5KQV.pdb')\n",
        "for model in structure:\n",
        "    for chain in model:\n",
        "        print(chain.get_id(), len(chain))\n",
        "        ln=[]\n",
        "        li=[]\n",
        "        for residue in chain:\n",
        "            if residue.get_resname()!='HOH':\n",
        "                li.append('{0:3}'.format(residue.id[1]))\n",
        "                ln.append(residue.get_resname())\n",
        "        print(' '.join(li))\n",
        "        print(' '.join(ln))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNHM9cYS4ji5"
      },
      "source": [
        "Вырежем только цепь Е."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiI8am_c4jAg"
      },
      "outputs": [],
      "source": [
        "!cat 5KQV.pdb | grep ' E ' > 5KQV_E.pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY3BqhHRuzwY"
      },
      "outputs": [],
      "source": [
        "p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "\n",
        "p.addModel(open('/content/5KQV_E.pdb','r').read(),'pdb')\n",
        "p.setStyle({'chain':'E'},{'cartoon':{'color':'green'}})\n",
        "p.setStyle({'resi':list(range(6,156))},{'cartoon':{'color':'yellow'}})\n",
        "\n",
        "p.zoomTo() # центрировать структуру\n",
        "p.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TcBA2wgjz18"
      },
      "source": [
        "Вырежем первые 150 остатков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jEwciZXDHoaG"
      },
      "outputs": [],
      "source": [
        "from Bio.PDB.StructureBuilder import StructureBuilder\n",
        "from Bio.PDB.PDBIO import PDBIO\n",
        "\n",
        "\n",
        "bb=StructureBuilder()\n",
        "\n",
        "bb.init_structure('part')\n",
        "bb.init_model(0)\n",
        "bb.init_chain('A')\n",
        "pdb=bb.get_structure()\n",
        "\n",
        "parser=PDBParser(QUIET=True)\n",
        "structure=parser.get_structure(\"5KQV\",'5KQV.pdb')\n",
        "\n",
        "for residue in structure[0]['E']:\n",
        "    if (residue.get_id()[1] in list(range(4, 154))):\n",
        "        pdb[0]['A'].add(residue)\n",
        "\n",
        "io = PDBIO()\n",
        "io.set_structure(pdb)\n",
        "io.save(\"5KQVpart.pdb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7GtwM5CqRb6"
      },
      "source": [
        "## 2. Binder design с помощью RFDiffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jRvSMgYrNl6"
      },
      "source": [
        "Используем RFdiffusion (https://github.com/RosettaCommons/RFdiffusion) для дизайна байндера."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV7Zj33hGZkP"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "! RFdiffusion/run_inference.py \\\n",
        "inference.input_pdb=5KQV_E.pdb \\\n",
        "'contigmap.contigs=[E4-153/0 200-200]' \\\n",
        "inference.output_prefix=result/rf_diff  \\\n",
        "inference.num_designs=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GdNvRMsQZw6"
      },
      "outputs": [],
      "source": [
        "p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "\n",
        "p.addModel(open('/content/result/rf_diff_0.pdb','r').read(),'pdb')\n",
        "\n",
        "p.setStyle({'chain':'B'},{'cartoon':{'color':'green'}})\n",
        "p.setStyle({'chain':'A'},{'cartoon':{'color':'blue'}})\n",
        "\n",
        "p.zoomTo() # центрировать структуру\n",
        "p.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap0kQ-6KKsMn"
      },
      "source": [
        "## 3. Определение hotspots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTexFPgFKu53"
      },
      "source": [
        "Для генерации байндера крайне желательно задать т.н. hotspots, то есть участки белка, которые должны взаимодействовать с байндером."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMYgktR56Xsh"
      },
      "source": [
        "Для определения хотспотов можно использовать инструменты для предсказания участков белок-белкового взаимодействия. Мы используем dMaSIF (https://github.com/FreyrS/dMaSIF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwyXxq_S15Ef"
      },
      "source": [
        "### MaSIF Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cOn8BF8JMg"
      },
      "source": [
        "Источник: https://colab.research.google.com/github/casperg92/MaSIF_colab/blob/main/dMaSIF_Colab_V1.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoytqYjr620q",
        "outputId": "2676b963-24d4-4bc9-a3d0-434a6ed27141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing PyKeops..\n",
            "Installing plyfile..\n",
            "Installing pyvtk..\n",
            "Installing nglview..\n",
            "Installing pdbparser..\n",
            "Installing reduce..\n",
            "fatal: destination path 'reduce' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies for dMaSIF\n",
        "\n",
        "%cd -q /content\n",
        "!rm -fr MaSIF_colab > /dev/null\n",
        "!git clone --quiet https://github.com/casperg92/MaSIF_colab.git > /dev/null\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"MaSIF_colab\")\n",
        "sys.path.append(\"MaSIF_colab/data_preprocessing\")\n",
        "\n",
        "\n",
        "!pip install torch_geometric &> /dev/null\n",
        "print('Installing PyKeops..')\n",
        "!pip install pykeops &> /dev/null\n",
        "print('Installing plyfile..')\n",
        "!pip install plyfile &> /dev/null\n",
        "print('Installing pyvtk..')\n",
        "!pip install pyvtk &> /dev/null\n",
        "print('Installing nglview..')\n",
        "!pip install -q nglview &> /dev/null\n",
        "print('Installing pdbparser..')\n",
        "!pip install pdbparser &> /dev/null\n",
        "print('Installing reduce..')\n",
        "!git clone --quiet https://github.com/rlabduke/reduce > /dev/null\n",
        "!cmake reduce &> /dev/null\n",
        "!make &> /dev/null\n",
        "!sudo make install &> /dev/null\n",
        "\n",
        "#Костыли\n",
        "\n",
        "with open('/content/MaSIF_colab/benchmark_models.py','r', encoding=\"utf-8\") as f:\n",
        "    b=f.read().replace('''from torch_geometric.nn import (\n",
        "    DynamicEdgeConv,\n",
        "    PointConv,\n",
        "    XConv,\n",
        "    fps,\n",
        "    radius,\n",
        "    global_max_pool,\n",
        "    knn_interpolate,\n",
        ")''','''from torch_geometric.nn import (\n",
        "    DynamicEdgeConv,\n",
        "    XConv,\n",
        "    fps,\n",
        "    radius,\n",
        "    global_max_pool,\n",
        "    knn_interpolate,\n",
        ")\n",
        "\n",
        "from typing import Callable, Optional, Union\n",
        "\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.inits import reset\n",
        "from torch_geometric.typing import (\n",
        "    Adj,\n",
        "    OptTensor,\n",
        "    PairOptTensor,\n",
        "    PairTensor,\n",
        "    SparseTensor,\n",
        "    torch_sparse,\n",
        ")\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
        "\n",
        "class PointNetConv(MessagePassing):\n",
        "    def __init__(self, local_nn: Optional[Callable] = None,\n",
        "                 global_nn: Optional[Callable] = None,\n",
        "                 add_self_loops: bool = True, **kwargs):\n",
        "        kwargs.setdefault('aggr', 'max')\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.local_nn = local_nn\n",
        "        self.global_nn = global_nn\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "        reset(self.local_nn)\n",
        "        reset(self.global_nn)\n",
        "\n",
        "    def forward(self, x: Union[OptTensor, PairOptTensor],\n",
        "                pos: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n",
        "\n",
        "        if not isinstance(x, tuple):\n",
        "            x: PairOptTensor = (x, None)\n",
        "\n",
        "        if isinstance(pos, Tensor):\n",
        "            pos: PairTensor = (pos, pos)\n",
        "\n",
        "        if self.add_self_loops:\n",
        "            if isinstance(edge_index, Tensor):\n",
        "                edge_index, _ = remove_self_loops(edge_index)\n",
        "                edge_index, _ = add_self_loops(\n",
        "                    edge_index, num_nodes=min(pos[0].size(0), pos[1].size(0)))\n",
        "            elif isinstance(edge_index, SparseTensor):\n",
        "                edge_index = torch_sparse.set_diag(edge_index)\n",
        "\n",
        "        # propagate_type: (x: PairOptTensor, pos: PairTensor)\n",
        "        out = self.propagate(edge_index, x=x, pos=pos, size=None)\n",
        "\n",
        "        if self.global_nn is not None:\n",
        "            out = self.global_nn(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j: Optional[Tensor], pos_i: Tensor,\n",
        "                pos_j: Tensor) -> Tensor:\n",
        "        msg = pos_j - pos_i\n",
        "        if x_j is not None:\n",
        "            msg = torch.cat([x_j, msg], dim=1)\n",
        "        if self.local_nn is not None:\n",
        "            msg = self.local_nn(msg)\n",
        "        return msg\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(local_nn={self.local_nn}, '\n",
        "                f'global_nn={self.global_nn})')\n",
        "\n",
        "''')\n",
        "with open('/content/MaSIF_colab/benchmark_models.py','w', encoding=\"utf-8\") as f:\n",
        "    f.write(b)\n",
        "\n",
        "with open('/content/MaSIF_colab/benchmark_layers.py','r', encoding=\"utf-8\") as f:\n",
        "    b=f.read()\n",
        "    b=b.replace('from torch_cluster import knn','')\n",
        "    b=b.replace('knns = {\"torch\": knn, \"keops\": keops_knn}','knns = {\"keops\": keops_knn}')\n",
        "\n",
        "with open('/content/MaSIF_colab/benchmark_layers.py','w', encoding=\"utf-8\") as f:\n",
        "    f.write(b)\n",
        "\n",
        "with open('/content/MaSIF_colab/data.py','r', encoding=\"utf-8\") as f:\n",
        "    b=f.read()\n",
        "    b=b.replace('def __cat_dim__(self, key, value)',\n",
        "                'def __cat_dim__(self, key, value, *args, **kwargs)')\n",
        "    b=b.replace('def __inc__(self, key, value)',\n",
        "                'def __inc__(self, key, value, *args, **kwargs)')\n",
        "with open('/content/MaSIF_colab/data.py','w', encoding=\"utf-8\") as f:\n",
        "    f.write(b)\n",
        "\n",
        "with open('/content/MaSIF_colab/data_iteration.py','r', encoding=\"utf-8\") as f:\n",
        "    b=f.read()\n",
        "    b=b.replace('in protein_pair.keys',\n",
        "                'in protein_pair.keys()')\n",
        "with open('/content/MaSIF_colab/data_iteration.py','w', encoding=\"utf-8\") as f:\n",
        "    f.write(b)\n",
        "\n",
        "with open('/content/MaSIF_colab/geometry_processing.py','r', encoding=\"utf-8\") as f:\n",
        "    b=f.read()\n",
        "    b=b.replace('S = torch.solve(PQt, PPt).solution',\n",
        "                'S = torch.linalg.solve(PQt, PPt)')\n",
        "with open('/content/MaSIF_colab/geometry_processing.py','w', encoding=\"utf-8\") as f:\n",
        "    f.write(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "cellView": "form",
        "id": "lhcB2qan6vKi"
      },
      "outputs": [],
      "source": [
        "#@title Change pdb path and chain name(s), then hit `Runtime` -> `Run all`\n",
        "#@markdown Note: the pdb file cannot contain an underscore ('_') in its name.\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create folder for the pdbs\n",
        "pred_dir = '/content/pdbs'\n",
        "isExist = os.path.exists(pred_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(pred_dir)\n",
        "\n",
        "# target pdb\n",
        "target_pdb = \"5KQVpart.pdb\" #@param {type:\"string\"}\n",
        "\n",
        "target_name = target_pdb.split('/')\n",
        "shutil.copyfile(target_pdb, pred_dir+target_name[-1])\n",
        "target_name = target_name[-1].split('.')\n",
        "\n",
        "if target_name[-1] == 'pdb':\n",
        "  target_name = target_name[0]\n",
        "else:\n",
        "  print('Please upload a valid .pdb file!')\n",
        "\n",
        "chain_name = 'A' #@param {type:\"string\"}\n",
        "chains = [chain_name]\n",
        "\n",
        "# Path to MaSIF weights\n",
        "#@markdown A resolution of 0.7 Angstrom gives a higher point cloud density and a higher performance. Different radii settings do not seem to impact performance.\n",
        "model_resolution = '0.7 Angstrom' #@param [\"1 Angstrom\", \"0.7 Angstrom\"]\n",
        "patch_radius = '9 Angstrom' #@param [\"9 Angstrom\", \"12 Angstrom\"]\n",
        "\n",
        "\n",
        "if patch_radius == '9 Angstrom':\n",
        "  if model_resolution == '1 Angstrom':\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_100sup_epoch64'\n",
        "    resolution = 1.0\n",
        "    radius = 9\n",
        "    sup_sampling = 100\n",
        "  else:\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_0.7res_150sup_epoch85'\n",
        "    resolution = 0.7\n",
        "    radius = 9\n",
        "    supsampling = 150\n",
        "\n",
        "elif patch_radius == '12 Angstrom':\n",
        "  if model_resolution == '1 Angstrom':\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_100sup_epoch71'\n",
        "    resolution = 1.0\n",
        "    radius = 12\n",
        "    supsampling = 100\n",
        "  else:\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_0.7res_150sup_epoch59'\n",
        "    resolution = 0.7\n",
        "    radius = 12\n",
        "    supsampling = 100\n",
        "\n",
        "\n",
        "# create new folders\n",
        "# chain dir\n",
        "chains_dir = '/content/chains'\n",
        "isExist = os.path.exists(chains_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(chains_dir)\n",
        "else:\n",
        "  files = glob.glob(chains_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "# npy folder\n",
        "npy_dir = '/content/npys'\n",
        "isExist = os.path.exists(npy_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(npy_dir)\n",
        "else:\n",
        "  files = glob.glob(npy_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "# Create folder for the embeddings\n",
        "pred_dir = '/content/preds'\n",
        "isExist = os.path.exists(pred_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(pred_dir)\n",
        "else:\n",
        "  files = glob.glob(pred_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "cellView": "form",
        "id": "m9qb7_yQ668c"
      },
      "outputs": [],
      "source": [
        "#@title Load functions\n",
        "\n",
        "import numpy as np\n",
        "import pykeops\n",
        "import torch\n",
        "from Bio.PDB import *\n",
        "from data_preprocessing.download_pdb import convert_to_npy\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.transforms import Compose\n",
        "import argparse\n",
        "import shutil\n",
        "import locale\n",
        "\n",
        "# Custom data loader and model:\n",
        "from data import ProteinPairsSurfaces, PairData, CenterPairAtoms, load_protein_npy\n",
        "from data import RandomRotationPairAtoms, NormalizeChemFeatures, iface_valid_filter\n",
        "from model import dMaSIF\n",
        "from data_iteration import iterate\n",
        "from helper import *\n",
        "\n",
        "# For showing the plot in nglview\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "import nglview as ng\n",
        "#import ipywidgets as widgets\n",
        "\n",
        "# For downloading files\n",
        "from google.colab import files\n",
        "\n",
        "def my_load_protein_pair(pdb_id, data_dir,single_pdb=False):\n",
        "    \"\"\"Loads a protein surface mesh and its features\"\"\"\n",
        "    pspl = pdb_id.split(\"_\")\n",
        "    p1_id = pspl[0] + \"_\" + pspl[1]\n",
        "    p2_id = pspl[0] + \"_\" + pspl[2]\n",
        "\n",
        "    p1 = load_protein_npy(p1_id, data_dir, center=False,single_pdb=single_pdb)\n",
        "    p2 = load_protein_npy(p2_id, data_dir, center=False,single_pdb=single_pdb)\n",
        "\n",
        "\n",
        "    protein_pair_data = PairData(\n",
        "        xyz_p1=None,\n",
        "        xyz_p2=None,\n",
        "        face_p1=None,\n",
        "        face_p2=None,\n",
        "        chemical_features_p1=None,\n",
        "        chemical_features_p2=None,\n",
        "        y_p1=None,\n",
        "        y_p2=None,\n",
        "        normals_p1=None,\n",
        "        normals_p2=None,\n",
        "        center_location_p1=None,\n",
        "        center_location_p2=None,\n",
        "        atom_coords_p1=p1[\"atom_coords\"],\n",
        "        atom_coords_p2=p2[\"atom_coords\"],\n",
        "        atom_types_p1=p1[\"atom_types\"],\n",
        "        atom_types_p2=p2[\"atom_types\"],\n",
        "    )\n",
        "    return protein_pair_data\n",
        "\n",
        "def generate_descr(model_path, output_path, pdb_file, npy_directory, radius, resolution,supsampling):\n",
        "    \"\"\"Generat descriptors for a MaSIF site model\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Network parameters\")\n",
        "    parser.add_argument(\"--experiment_name\", type=str, default=model_path)\n",
        "    parser.add_argument(\"--use_mesh\", type=bool, default=False)\n",
        "    parser.add_argument(\"--embedding_layer\",type=str,default=\"dMaSIF\")\n",
        "    parser.add_argument(\"--curvature_scales\",type=list,default=[1.0, 2.0, 3.0, 5.0, 10.0])\n",
        "    parser.add_argument(\"--resolution\",type=float,default=resolution)\n",
        "    parser.add_argument(\"--distance\",type=float,default=1.05)\n",
        "    parser.add_argument(\"--variance\",type=float,default=0.1)\n",
        "    parser.add_argument(\"--sup_sampling\", type=int, default=supsampling)\n",
        "    parser.add_argument(\"--atom_dims\",type=int,default=6)\n",
        "    parser.add_argument(\"--emb_dims\",type=int,default=16)\n",
        "    parser.add_argument(\"--in_channels\",type=int,default=16)\n",
        "    parser.add_argument(\"--orientation_units\",type=int,default=16)\n",
        "    parser.add_argument(\"--unet_hidden_channels\",type=int,default=8)\n",
        "    parser.add_argument(\"--post_units\",type=int,default=8)\n",
        "    parser.add_argument(\"--n_layers\", type=int, default=3)\n",
        "    parser.add_argument(\"--radius\", type=float, default=radius)\n",
        "    parser.add_argument(\"--k\",type=int,default=40)\n",
        "    parser.add_argument(\"--dropout\",type=float,default=0.0)\n",
        "    parser.add_argument(\"--site\", type=bool, default=True) # set to true for site model\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
        "    parser.add_argument(\"--search\",type=bool,default=False) # Set to true for search model\n",
        "    parser.add_argument(\"--single_pdb\",type=str,default=pdb_file)\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--random_rotation\",type=bool,default=False)\n",
        "    parser.add_argument(\"--device\", type=str, default=\"cpu\")\n",
        "    #parser.add_argument(\"--single_protein\",type=bool,default=True)\n",
        "    parser.add_argument(\"--single_protein\",type=bool,default=True) # set to false for site\n",
        "    parser.add_argument(\"--no_chem\", type=bool, default=False)\n",
        "    parser.add_argument(\"--no_geom\", type=bool, default=False)\n",
        "\n",
        "    args = parser.parse_args(\"\")\n",
        "\n",
        "    model_path = args.experiment_name\n",
        "    save_predictions_path = Path(output_path)\n",
        "\n",
        "    # Ensure reproducability:\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "\n",
        "    # Load the train and test datasets:\n",
        "    transformations = (\n",
        "        Compose([NormalizeChemFeatures(), CenterPairAtoms(), RandomRotationPairAtoms()])\n",
        "        if args.random_rotation\n",
        "        else Compose([NormalizeChemFeatures()])\n",
        "    )\n",
        "\n",
        "    if args.single_pdb != \"\":\n",
        "        single_data_dir = Path(npy_directory)\n",
        "        test_dataset = [my_load_protein_pair(args.single_pdb, single_data_dir, single_pdb=True)]\n",
        "        test_pdb_ids = [args.single_pdb]\n",
        "\n",
        "    # PyTorch geometric expects an explicit list of \"batched variables\":\n",
        "    batch_vars = [\"xyz_p1\", \"xyz_p2\", \"atom_coords_p1\", \"atom_coords_p2\"]\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=args.batch_size, follow_batch=batch_vars\n",
        "    )\n",
        "\n",
        "    net = dMaSIF(args)\n",
        "    # net.load_state_dict(torch.load(model_path, map_location=args.device))\n",
        "    net.load_state_dict(torch.load(model_path, map_location=args.device)[\"model_state_dict\"])\n",
        "    net = net.to(args.device)\n",
        "\n",
        "    # Perform one pass through the data:\n",
        "    info = iterate(\n",
        "        net,\n",
        "        test_loader,\n",
        "        None,\n",
        "        args,\n",
        "        test=True,\n",
        "        save_path=save_predictions_path,\n",
        "        pdb_ids=test_pdb_ids,\n",
        "    )\n",
        "    return info\n",
        "\n",
        "\n",
        "\n",
        "def show_pointcloud(main_pdb, coord_file, emb_file):\n",
        "  # Normalize embedding to represent a b-factor value between 0-100\n",
        "  b_factor = []\n",
        "  for emb in emb_file:\n",
        "      b_factor.append(emb[-2])\n",
        "\n",
        "  # b_factor = [(float(i)-min(b_factor))/(max(b_factor)-min(b_factor)) for i in b_factor]\n",
        "\n",
        "  # writing a pseudo pdb of all points using their coordinates and H atom.\n",
        "  with open(\"pointcloud.pdb\",'w') as f:\n",
        "    for i in range(len(coord_file)):\n",
        "\n",
        "      points = coord_file[i]\n",
        "      s=\"ATOM  {:5d}  H   XYZ A   1    {:8.3f}{:8.3f}{:8.3f}  1.00{:6.2f}           H  \\n\".format(i+1,i+1,\n",
        "                                                                                                   points[0],\n",
        "                                                                                                   points[1],\n",
        "                                                                                                   points[2],\n",
        "                                                                                                   b_factor[i]*100)\n",
        "      f.write(s)\n",
        "\n",
        "  # reading the psudo PDB we generated above for the point cloud.\n",
        "  coordPDB = \"pointcloud.pdb\"\n",
        "  view = ng.NGLWidget()\n",
        "  view.add_component(ng.FileStructure(os.path.join(\"/content\", coordPDB)), defaultRepresentation=False)\n",
        "\n",
        "  # representation with our customized colorscheme.\n",
        "  view.add_representation('point',\n",
        "                          useTexture = 1,\n",
        "                          pointSize = 2,\n",
        "                          colorScheme = \"bfactor\",\n",
        "                          colorDomain = [100.0, 0.0],\n",
        "                          colorScale = 'rwb',\n",
        "                          selection='_H')\n",
        "\n",
        "  view.add_component(ng.FileStructure(os.path.join(\"/content\", main_pdb)))\n",
        "  view.background = 'black'\n",
        "  return view\n",
        "\n",
        "def show_structure(main_pdb):\n",
        "  # reading the psudo PDB we generated above for the point cloud.\n",
        "  view = ng.NGLWidget()\n",
        "\n",
        "  view.add_component(ng.FileStructure(main_pdb), defaultRepresentation=False)\n",
        "  view.add_representation(\"cartoon\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
        "  view.add_representation(\"ball+stick\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
        "  view.background = 'black'\n",
        "  return view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvB4nPLW6-fh",
        "outputId": "38ee186c-2833-414a-c52d-3b2d19032af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title Run MaSIF\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "tmp_pdb = '/content/pdbs/tmp_1.pdb'\n",
        "shutil.copyfile(target_pdb, tmp_pdb)\n",
        "\n",
        "# Remove protons if there are any\n",
        "!reduce -Trim -Quiet /content/pdbs/tmp_1.pdb > /content/pdbs/tmp_2.pdb\n",
        "# Add protons\n",
        "!reduce -HIS -Quiet /content/pdbs/tmp_2.pdb > /content/pdbs/tmp_3.pdb\n",
        "\n",
        "tmp_pdb = '/content/pdbs/tmp_3.pdb'\n",
        "shutil.copyfile(tmp_pdb, target_pdb)\n",
        "# Generate the surface features\n",
        "convert_to_npy(target_pdb, chains_dir, npy_dir, chains)\n",
        "\n",
        "# Generate the embeddings\n",
        "pdb_name = \"{n}_{c}_{c}\".format(n= target_name, c=chain_name)\n",
        "info = generate_descr(model_path, pred_dir, pdb_name, npy_dir, radius, resolution, supsampling)\n",
        "\n",
        "# In info I hardcoded memory usage to 0 so MaSIF would run on the CPU. We might want to change this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDE3DEmT7BQp",
        "outputId": "d07a55b2-b124-449f-f720-7de28b043f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorted on residue contribution (high to low\n",
            "118 0.9089528\n",
            "88 0.9005107\n",
            "96 0.88948977\n",
            "94 0.8855943\n",
            "109 0.8851982\n",
            "107 0.86690444\n",
            "113 0.86447966\n",
            "89 0.8602897\n",
            "14 0.83060646\n",
            "46 0.8148788\n",
            "108 0.80655044\n",
            "110 0.7966335\n",
            "121 0.7882006\n",
            "128 0.7850416\n",
            "144 0.78006583\n",
            "97 0.77719116\n",
            "83 0.7698663\n",
            "4 0.7564565\n",
            "130 0.75584483\n",
            "80 0.7531414\n",
            "62 0.7491793\n",
            "7 0.744514\n",
            "86 0.7407951\n",
            "36 0.7354739\n",
            "73 0.72647625\n",
            "147 0.72275585\n",
            "129 0.72260046\n",
            "53 0.7150244\n",
            "127 0.7115184\n",
            "105 0.69669217\n",
            "78 0.69633853\n",
            "39 0.69068295\n",
            "47 0.6887554\n",
            "153 0.6860921\n",
            "114 0.6834681\n",
            "138 0.68142754\n",
            "102 0.6803827\n",
            "141 0.6761352\n",
            "90 0.6674489\n",
            "37 0.6660379\n",
            "139 0.66483307\n",
            "67 0.6593434\n",
            "70 0.6587157\n",
            "143 0.6577749\n",
            "131 0.6518266\n",
            "133 0.64116365\n",
            "65 0.64060944\n",
            "71 0.6394651\n",
            "81 0.6362723\n",
            "30 0.6346817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/Bio/PDB/PDBParser.py:395: PDBConstructionWarning: Ignoring unrecognized record 'END' at line 2531\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#@title Generate PDBs for hotspot atoms and residues\n",
        "list_top_n_hotspot_residues = 50 #@param {type:\"integer\"}\n",
        "\n",
        "from Bio.PDB.PDBParser import PDBParser\n",
        "from pykeops.numpy import LazyTensor\n",
        "\n",
        "parser=PDBParser(PERMISSIVE=1)\n",
        "structure=parser.get_structure(\"structure\", target_pdb)\n",
        "\n",
        "coord = np.load(\"preds/{n}_{c}_predcoords.npy\".format(n= target_name, c=chain_name))\n",
        "embedding = np.load(\"/content/preds/{n}_{c}_predfeatures_emb1.npy\".format(n= target_name, c=chain_name))\n",
        "atom_coords = np.stack([atom.get_coord() for atom in structure.get_atoms()])\n",
        "\n",
        "b_factor = embedding[:, -2]\n",
        "# b_factor = (b_factor - min(b_factor)) / (max(b_factor) - min(b_factor))\n",
        "\n",
        "x_i = LazyTensor(atom_coords[:, None, :])\n",
        "y_j = LazyTensor(coord[None, :, :])\n",
        "dists = ((x_i - y_j) ** 2).sum(-1)\n",
        "nn_ind = dists.argmin(dim=1)\n",
        "dists=dists.min(dim=1)\n",
        "\n",
        "atom_b_factor = b_factor[nn_ind]\n",
        "dist_thresh = 2.0\n",
        "atom_b_factor[dists > dist_thresh] = 0.0\n",
        "\n",
        "for i, atom in enumerate(structure.get_atoms()):\n",
        "    atom.set_bfactor(atom_b_factor[i] * 100)\n",
        "\n",
        "# Create folder for the embeddings\n",
        "pred_dir = '/content/output'\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "# Save pdb file with per-atom b-factors\n",
        "io = PDBIO()\n",
        "io.set_structure(structure)\n",
        "io.save(\"/content/output/per_atom_binding.pdb\")\n",
        "\n",
        "atom_residues = np.array([atom.get_parent().id[1] for atom in structure.get_atoms()])\n",
        "\n",
        "hotspot_res = {}\n",
        "for residue in structure.get_residues():\n",
        "    res_id = residue.id[1]\n",
        "    res_b_factor = np.max(atom_b_factor[atom_residues == res_id])\n",
        "    hotspot_res[res_id] = res_b_factor\n",
        "    for atom in residue.get_atoms():\n",
        "        atom.set_bfactor(res_b_factor * 100)\n",
        "\n",
        "# Save pdb file with per-residue b-factors\n",
        "io = PDBIO()\n",
        "io.set_structure(structure)\n",
        "io.save(\"/content/output/per_resi_binding.pdb\")\n",
        "\n",
        "if list_top_n_hotspot_residues>0:\n",
        "  print('Sorted on residue contribution (high to low')\n",
        "  for w in sorted(hotspot_res, key=hotspot_res.get, reverse=True)[:list_top_n_hotspot_residues]:\n",
        "    print(w, hotspot_res[w])\n",
        "    if hotspot_res[w]==0:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nc7502OO7Geu"
      },
      "outputs": [],
      "source": [
        "#@title Plot output\n",
        "#@markdown Blue identifies non-binding and red identifies binding interaction sites. Rerun this cell if you want to change the plotted structure.\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "plot_structure = 'Residues' #@param [\"Pointcloud\", \"Residues\", \"Atoms\"]\n",
        "\n",
        "## file addresses\n",
        "if plot_structure == 'Pointcloud':\n",
        "  view = show_pointcloud(target_pdb, coord, embedding)\n",
        "elif plot_structure == \"Residues\":\n",
        "  view = show_structure('/content/output/per_resi_binding.pdb')\n",
        "elif plot_structure == \"Atoms\":\n",
        "  view = show_structure('/content/output/per_atom_binding.pdb')\n",
        "\n",
        "view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoFIfhEW8ZDn"
      },
      "source": [
        "## 4. Fold conditioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA07Lg8kMRHN"
      },
      "source": [
        "Попробуем задизайнить белок-связывающее антитело. Для этого используем функционал fold conditioning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb_ERwVM9FdS"
      },
      "source": [
        "Скачаем структуру антитела."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgDyJilY6miY"
      },
      "outputs": [],
      "source": [
        "!wget https://files.rcsb.org/download/7DET.pdb\n",
        "!cat 7DET.pdb  | grep ' B ' > 7DET_B.pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faTWrqhoA4hO"
      },
      "outputs": [],
      "source": [
        "p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "\n",
        "p.addModel(open('/content/7DET_B.pdb','r').read(),'pdb')\n",
        "p.setStyle({'chain':'B'},{'cartoon':{'color':'blue'}})\n",
        "\n",
        "p.zoomTo() # центрировать структуру\n",
        "p.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X27vASfRMiZJ"
      },
      "source": [
        "Сгенерируем файл со вторичной структурой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uwUEcEL8CEd"
      },
      "outputs": [],
      "source": [
        "! RFdiffusion/helper_scripts/make_secstruc_adj.py --input_pdb ./7DET_B.pdb --out_dir antibody_secstruc/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ4wqOlVrJF-"
      },
      "source": [
        "Запустим RFDiffusion. Синтаксис здесь будет несколько отличаться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDzK0oeD-Jbz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "! RFdiffusion/run_inference.py \\\n",
        "scaffoldguided.scaffoldguided=True \\\n",
        "scaffoldguided.target_pdb=True \\\n",
        "scaffoldguided.target_path=5KQVpart.pdb \\\n",
        "'ppi.hotspot_res=[E57,E81,E89]'  \\\n",
        "scaffoldguided.scaffold_dir=antibody_secstruc/ \\\n",
        "inference.num_designs=1 \\\n",
        "inference.output_prefix=result/rf_diff_fold_hotspot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmxALcc9-T4S"
      },
      "outputs": [],
      "source": [
        "p = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "\n",
        "p.addModel(open('/content/result/rf_diff_fold_hotspot_0.pdb','r').read(),'pdb')\n",
        "p.setStyle({'chain':'A'},{'cartoon':{'color':'green'}})\n",
        "p.setStyle({'chain':'B'},{'cartoon':{'color':'blue'}})\n",
        "p.setStyle({'chain':'B','resi':[231+57,231+81,231+89]},\n",
        " {'cartoon':{'color':'yellow'},'stick':{'colorscheme':'yellowCarbon'}})\n",
        "\n",
        "p.zoomTo()\n",
        "p.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZiLG2iKOJdM"
      },
      "outputs": [],
      "source": [
        "parser=PDBParser(QUIET=True)\n",
        "structure=parser.get_structure(\"5KQV\",'result/rf_diff_fold_hotspot_0.pdb')\n",
        "for model in structure:\n",
        "    for chain in model:\n",
        "        print(chain.get_id(), len(chain))\n",
        "        ln=[]\n",
        "        li=[]\n",
        "        for residue in chain:\n",
        "            if residue.get_resname()!='HOH':\n",
        "                li.append('{0:3}'.format(residue.id[1]))\n",
        "                ln.append(residue.get_resname())\n",
        "        print(' '.join(li))\n",
        "        print(' '.join(ln))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
